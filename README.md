# UGC Studio

UGC Studio is a Next.js application that blends OpenAI Assistants, Google Gemini 2.5 Flash, and Supabase to help marketers ideate and render product-ready UGC (user-generated content) imagery. The interface mirrors a creative brief workflow: upload a product hero image, describe the audience, let OpenAI draft six campaign scenarios, then send the selected concepts to Gemini for photorealistic image generation. Supabase is used to persist metadata about each generation for later reporting or analytics.

## Features

- 🔁 **Automatic Assistant Threads** – A fresh OpenAI Assistant thread is created every time a visitor lands on the experience.
- 🧠 **Scenario Ideation** – Product context is passed to the Assistant API which returns six JSON-formatted scenarios ready for review.
- 🎨 **Fine-grained Render Controls** – Tailwind-powered UI that matches the provided design for tweaking style, tone, orientation, and enhancements.
- 🖼️ **Gemini 2.5 Flash Rendering** – Selected scenarios and the uploaded product reference image are sent to Google Gemini for the final UGC output.
- 🗄️ **Supabase Storage** – Each render (thread, scenario metadata, and settings) is logged to Supabase for downstream analysis.

## Prerequisites

1. **Node.js 18+** and **npm** installed locally.
2. Accounts and API keys for:
   - [OpenAI](https://platform.openai.com/) with an Assistant already created. Note the assistant ID.
   - [Google AI Studio](https://ai.google.dev/) for Gemini 2.5 Flash API access.
   - [Supabase](https://supabase.com/) project with a table named `ugc_generations`.

Create the table in Supabase with a SQL migration similar to:

```sql
create table if not exists ugc_generations (
  id bigint generated by default as identity primary key,
  created_at timestamptz default timezone('utc', now()),
  thread_id text,
  scenario_id text,
  scenario_title text,
  scenario_summary text,
  settings jsonb
);
```

## Environment variables

Create a `.env.local` file in the project root with the following keys:

```bash
OPENAI_API_KEY=sk-...
OPENAI_ASSISTANT_ID=asst_...
GOOGLE_GEMINI_API_KEY=...
# Optional: override the default Gemini model (defaults to gemini-2.5-flash-nano-banana)
# GOOGLE_GEMINI_IMAGE_MODEL=gemini-2.5-flash

SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
# Optional, used if you plan to call Supabase from the browser
# NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
# NEXT_PUBLIC_SUPABASE_ANON_KEY=anon-key
```

> **Security note**: the Supabase Service Role key should only be used on the server. Do not expose it to the client bundle.

## Installation

```bash
npm install
```

## Local development

```bash
npm run dev
```

Visit [http://localhost:3000](http://localhost:3000) to interact with the UI. Upload a product image, describe your audience, request scenarios, and then trigger the Gemini generation.

## Linting

Run ESLint to ensure code quality:

```bash
npm run lint
```

## Project structure

- `app/` – App Router pages and API routes.
  - `api/openai/thread` – Creates a new OpenAI Assistant thread on demand.
  - `api/openai/scenarios` – Sends the product brief to OpenAI and enforces a JSON response with six scenarios.
  - `api/gemini/generate` – Calls the Gemini 2.5 Flash API to render images and logs metadata to Supabase.
- `components/` – (Reserved for future UI components.)
- `lib/` – Shared utilities, schemas, and Supabase helpers.

## Production build

```bash
npm run build
npm start
```

Deploy to your preferred platform (Vercel, Supabase, etc.) and set the same environment variables in the hosting environment.
